{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2023-01-02T14:23:27.084034Z",
     "iopub.status.busy": "2023-01-02T14:23:27.083332Z",
     "iopub.status.idle": "2023-01-02T14:23:30.127943Z",
     "shell.execute_reply": "2023-01-02T14:23:30.126890Z",
     "shell.execute_reply.started": "2023-01-02T14:23:27.083961Z"
    }
   },
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import os, math, time, random\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    " \n",
    "import cv2\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    " # skimage\n",
    "from skimage.io import imread \n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from skimage import data, color\n",
    "\n",
    "# pil\n",
    "from PIL import Image as pil_image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# from keras\n",
    "import keras\n",
    "from keras.layers import Concatenate, Input\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  MaxPooling2D, BatchNormalization, Flatten\n",
    "from keras.layers import Input, Conv2D, Activation,  MaxPool2D, AveragePooling2D\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, GlobalMaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from keras.activations import relu, sigmoid\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.nasnet import NASNetMobile\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "#from keras.applications.resnet import ResNet101\n",
    "\n",
    "# scikit learn helper functions\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-02T14:23:30.129849Z",
     "iopub.status.busy": "2023-01-02T14:23:30.129523Z",
     "iopub.status.idle": "2023-01-02T14:23:30.134235Z",
     "shell.execute_reply": "2023-01-02T14:23:30.133113Z",
     "shell.execute_reply.started": "2023-01-02T14:23:30.129771Z"
    }
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 32 # in the given original size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-02T14:23:30.135859Z",
     "iopub.status.busy": "2023-01-02T14:23:30.135578Z",
     "iopub.status.idle": "2023-01-02T14:23:30.523553Z",
     "shell.execute_reply": "2023-01-02T14:23:30.445000Z",
     "shell.execute_reply.started": "2023-01-02T14:23:30.135802Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Given files: ', os.listdir('../'))\n",
    "# data shapes\n",
    "print('train images: ', len(os.listdir('train/train')))\n",
    "print('test images: ', len(os.listdir('test/test')))\n",
    "\n",
    "# folders\n",
    "train_folder = 'train/train'\n",
    "test_folder = 'test/test'\n",
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-02T14:23:30.445786Z",
     "iopub.status.idle": "2023-01-02T14:23:30.446378Z"
    }
   },
   "outputs": [],
   "source": [
    "train_images_path = glob('train/train/*.jpg')\n",
    "test_images_path = glob('test/test/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-02T14:23:30.446931Z",
     "iopub.status.idle": "2023-01-02T14:23:30.447276Z"
    }
   },
   "outputs": [],
   "source": [
    "# retunrs a complete path to a image with Image name\n",
    "def expand_path(path):\n",
    "    if os.path.isfile('train/train/' + path):\n",
    "        return 'train/train/' + path\n",
    "    if os.path.isfile('test/test/' + path):\n",
    "        return 'test/test/' + path\n",
    "    return path\n",
    "\n",
    "# returns a resized black and white PIL Image object\n",
    "def pil_image_load(image):\n",
    "    image_path = expand_path(image)\n",
    "    image = pil_image.open(image_path)#.convert('L')\n",
    "    return image.resize((IMG_SIZE, IMG_SIZE))\n",
    "    #return image\n",
    "    \n",
    "# load the resized image\n",
    "def read_image(img_path, resized_shape=None):\n",
    "    # expanding img_path to complete image path\n",
    "    img_path = expand_path(img_path)\n",
    "    image = imread(img_path)\n",
    "    gray_image = color.rgb2gray(image)\n",
    "    rgb_image = color.gray2rgb(gray_image)\n",
    "    if resized_shape:\n",
    "        image_resized = resize(rgb_image,(resized_shape,resized_shape, 3))\n",
    "        return image_resized[:,:]/255\n",
    "    return rgb_image[:,:]/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-02T14:23:30.448092Z",
     "iopub.status.idle": "2023-01-02T14:23:30.448427Z"
    }
   },
   "outputs": [],
   "source": [
    "# train data dataframe\n",
    "train_df['image'] = train_df['id'].apply(lambda path: read_image(path))\n",
    "\n",
    "# creating test dataframe\n",
    "test_df = pd.DataFrame(columns=[\"id\", \"image\"])\n",
    "test_df['id'] = os.listdir('test/test/')\n",
    "test_df['image'] = test_df['id'].apply(lambda path: read_image(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-02T14:23:30.449000Z",
     "iopub.status.idle": "2023-01-02T14:23:30.449383Z"
    }
   },
   "outputs": [],
   "source": [
    "# some visualizations \n",
    "random.shuffle(train_images_path)\n",
    "fig, ax = plt.subplots(2,5, figsize=(15,6))\n",
    "fig.suptitle('Some aerial images',fontsize=16)\n",
    "\n",
    "df = shuffle(train_df)\n",
    "for i, item in enumerate(df.values[15:20]):\n",
    "    image = pil_image.open(expand_path(item[0]))\n",
    "    ax[0,i].imshow(image)\n",
    "    ax[0, i].set_title('Has Cactus = %d' % (item[1]))\n",
    "ax[0,0].set_ylabel('train images', size='large')\n",
    "\n",
    "for i, path in enumerate(test_images_path[:5]):\n",
    "    image = pil_image.open(path)\n",
    "    #image = image.resize((IMG_SIZE, IMG_SIZE))\n",
    "    ax[1,i].imshow(image)\n",
    "ax[1,0].set_ylabel('test images', size='large');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-02T14:23:30.453047Z",
     "iopub.status.idle": "2023-01-02T14:23:30.453381Z"
    }
   },
   "outputs": [],
   "source": [
    "# returns a batch of image for training\n",
    "def train_batch(train_df):\n",
    "    batch_size = train_df.shape[0]\n",
    "    images = train_df.image.values\n",
    "    first_image = images[0]\n",
    "    x_train = []\n",
    "    y_train = train_df.has_cactus.values\n",
    "    for i, image in enumerate(images):\n",
    "        x_train.append(image.tolist())\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = y_train.reshape(len(y_train), 1)\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "class CustomCNN(tf.keras.Sequential):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv1 = Conv2D(128, (3, 3), strides=(1, 1), input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "        self.batchnorm1 = BatchNormalization()\n",
    "        self.act1 = Activation('relu')\n",
    "        self.pool1 = MaxPooling2D((2, 2))\n",
    "\n",
    "        self.conv2 = Conv2D(256, (3, 3), strides=(1, 1))\n",
    "        self.batchnorm2 = BatchNormalization()\n",
    "        self.act2 = Activation('relu')\n",
    "        self.pool2 = MaxPooling2D((2, 2))\n",
    "\n",
    "        self.conv3 = Conv2D(128, (3, 3), strides=(1, 1))\n",
    "        self.batchnorm3 = BatchNormalization()\n",
    "        self.act3 = Activation('relu')\n",
    "        self.pool3 = MaxPooling2D((2, 2))\n",
    "\n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = Dense(512, activation='relu')\n",
    "        self.dropout1 = Dropout(0.5)\n",
    "        self.dense2 = Dense(256, activation='relu')\n",
    "        self.dropout2 = Dropout(0.25)\n",
    "        self.dense3 = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.act3(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.dense3(x)\n",
    "\n",
    "        return x\n",
    "    def build(self,input_shape):\n",
    "        self.built=True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-02T14:23:30.449855Z",
     "iopub.status.idle": "2023-01-02T14:23:30.450328Z"
    }
   },
   "outputs": [],
   "source": [
    "# CNN model\n",
    "def CNN():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(128, (3, 3), strides = (1, 1), input_shape = (IMG_SIZE, IMG_SIZE, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(256, (3, 3), strides = (1,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), strides = (1,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # fully connected layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    # output\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # compiling\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-02T14:23:30.450792Z",
     "iopub.status.idle": "2023-01-02T14:23:30.451296Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ref: https://www.kaggle.com/CVxTz/cnn-starter-nasnet-mobile-0-9709-lb\n",
    "def NASNetMoibleClassifier():\n",
    "    inputs = Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    base_model = NASNetMobile(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))#, weights=None\n",
    "    x = base_model(inputs)\n",
    "    \n",
    "    out1 = GlobalMaxPooling2D()(x)\n",
    "    out2 = GlobalAveragePooling2D()(x)\n",
    "    out3 = Flatten()(x)\n",
    "    \n",
    "    out = Concatenate(axis=-1)([out1, out2, out3])\n",
    "    out = Dropout(0.5)(out)\n",
    "    out = Dense(1, activation=\"softmax\")(out)\n",
    "    \n",
    "    model = Model(inputs, out)\n",
    "    model.compile(optimizer=Adam(0.0001), loss='binary_crossentropy', metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-02T14:23:30.451806Z",
     "iopub.status.idle": "2023-01-02T14:23:30.452318Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ref: https://www.kaggle.com/CVxTz/cnn-starter-nasnet-mobile-0-9709-lb\n",
    "def VGGModel():\n",
    "    model_vg = VGG16(weights='imagenet',include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    #model_vg.trainable = False\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(model_vg)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-02T14:23:30.453929Z",
     "iopub.status.idle": "2023-01-02T14:23:30.454321Z"
    }
   },
   "outputs": [],
   "source": [
    "#model = CNN()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-02T14:23:30.454826Z",
     "iopub.status.idle": "2023-01-02T14:23:30.455221Z"
    }
   },
   "outputs": [],
   "source": [
    "# training data\n",
    "X_train, y_train = train_batch(train_df)\n",
    "print(len(X_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-02T14:23:30.455679Z",
     "iopub.status.idle": "2023-01-02T14:23:30.456026Z"
    }
   },
   "outputs": [],
   "source": [
    " # batch train (with batch load) the model with training data\n",
    "def train_model(model, X_train, y_train,pngName,accuracyName='accuracy', epochs=5, verbose=None):\n",
    "    begin = time.time()\n",
    "    # checkpoint\n",
    "    checkpointer = ModelCheckpoint(filepath='weights.hdf5', monitor='val_'+accuracyName, verbose=0, save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', verbose=1, patience=5)\n",
    "    modelHistory=[]\n",
    "    modelLoss=[]\n",
    "    modelAcc=[]\n",
    "    modelValAcc=[]\n",
    "    modelValLoss=[]\n",
    "    for i in range(1, epochs + 1):\n",
    "        #print('************************************')\n",
    "        #print('Epoch: ', i, '/', epochs)\n",
    "        #print('************************************')\n",
    "        if verbose:\n",
    "            verbose = verbose\n",
    "        # fitting\n",
    "        model.fit(X_train, y_train, verbose=verbose, callbacks=[checkpointer, early_stopping], validation_split=0.1, shuffle=True)\n",
    "        print(model.history.history)\n",
    "        modelLoss.append(model.history.history['loss'])\n",
    "        modelAcc.append(model.history.history[accuracyName])\n",
    "        modelValAcc.append(model.history.history['val_'+accuracyName])\n",
    "        modelValLoss.append(model.history.history['val_loss'])\n",
    "\n",
    "        \n",
    "        # plot the loss values\n",
    "\n",
    "\n",
    "    # done!\n",
    "    plt.plot(modelAcc)\n",
    "    plt.plot(modelValAcc)\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.savefig(pngName+'valacc.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    # plot the accuracy values\n",
    "    plt.plot(modelAcc)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy values')\n",
    "    plt.legend()\n",
    "    plt.savefig(pngName+'accuracy.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # plot the accuracy values\n",
    "    plt.plot(modelLoss)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss values')\n",
    "    plt.legend()\n",
    "    plt.savefig(pngName+'loss.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    # plot the Vall Losss values\n",
    "    plt.plot(modelAcc)\n",
    "    plt.plot(modelValLoss)\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.savefig(pngName+'valloss.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    #accuracyYazdir(accuracy_score(Y_test, predicted.round()),\"selectedModelText\"+\"_accuracy\"+ str(index))\n",
    "    print(\"CNN/\")\n",
    "    print(conf)\n",
    "    #  confMatrix(cf_matrix=conf,pngName=\"CNN/\"+\"_karisiklik_matris\"+str(index))\n",
    "    \n",
    "    \n",
    "    \n",
    "    elapsed = time.time() - begin\n",
    "    print('total training time: ', elapsed)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def accuracyYazdir(acc,pngName):\n",
    "\n",
    "  plt.plot([0, 1], [0, 1], 'k--')\n",
    "  plt.plot(acc, acc, 'bo', label='Accuracy')\n",
    "  plt.title('Accuracy')\n",
    "  plt.xlabel('Accuracy')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.legend()\n",
    "  plt.savefig(pngName+'.png', dpi=300, bbox_inches='tight')\n",
    "  plt.show()\n",
    "\n",
    "def confMatrix(cf_matrix,pngName):\n",
    "  from sklearn.metrics import confusion_matrix\n",
    "  import sklearn.metrics as mt\n",
    "  group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "  group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                  cf_matrix.flatten()]\n",
    "  group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                      cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "  labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "            zip(group_names,group_counts,group_percentages)]\n",
    "  labels = np.asarray(labels).reshape(2,2)\n",
    "  ax = sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "  ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "  ax.set_xlabel('\\nPredicted Values')\n",
    "  ax.set_ylabel('Actual Values ');\n",
    "  ## Ticket labels - List must be in alphabetical order\n",
    "  ax.xaxis.set_ticklabels(['False','True'])\n",
    "  ax.yaxis.set_ticklabels(['False','True'])\n",
    "  plt.legend()\n",
    "  ## Display the visualization of the Confusion Matrix.\n",
    "  plt.savefig(pngName+'.png', dpi=300, bbox_inches='tight')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def benimModel():\n",
    "    model = CustomCNN()\n",
    "    model.build(input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_sz=2\n",
    "fileName=\"\"\n",
    "model=CNN()\n",
    "batch_sz=64\n",
    "selected_cb=1\n",
    "if (selected_cb==1):\n",
    "    fileName=\"\"\n",
    "if (selected_cb==2):\n",
    "    fileName=\"\"\n",
    "if (selected_cb==3):\n",
    "    fileName=\"\"\n",
    "if (selected_cb==4):\n",
    "    fileName=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "kf = KFold(n_splits=2)\n",
    "x=X_train\n",
    "y=y_train\n",
    "accuracies = []\n",
    "confs = []\n",
    "accs = []\n",
    "index=1\n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        Y_train, Y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        if (selected_cb==1):\n",
    "            model=CNN()\n",
    "            model.summary()\n",
    "            md1 = train_model(model, x_train, Y_train,'CNN/', epochs=3, verbose=1)\n",
    "           #  create lists for the loss and accuracy values        \n",
    "            predicted = md1.predict(x_test)\n",
    "            conf = confusion_matrix(Y_test, predicted)\n",
    "            confMatrix(cf_matrix=conf,pngName=\"CNN/\"+\"_karisiklik_matris\"+str(index))\n",
    "            md1.save('CNN/model.h5')\n",
    "            v\n",
    "        if (selected_cb==2):\n",
    "            model=VGGModel()\n",
    "            model.summary()\n",
    "            md1 = train_model(model, x_train, Y_train,'VGGModel/', epochs=3, verbose=1)\n",
    "            predicted = md1.predict(x_test).astype(\"int\")\n",
    "            conf = confusion_matrix(Y_test, predicted)\n",
    "            confMatrix(cf_matrix=conf,pngName=\"VGGModel/\"+\"_karisiklik_matris\"+str(index))\n",
    "            md1.save('VGGModel/model.h5') \n",
    "            \n",
    "        if (selected_cb==3):        \n",
    "            model=NASNetMoibleClassifier()\n",
    "            model.summary()\n",
    "            md1 = train_model(model, x_train, Y_train,'NASNetMoibleClassifier/','acc', epochs=3, verbose=1)\n",
    "            predicted = md1.predict(x_test).astype(\"int\")\n",
    "            conf = confusion_matrix(Y_test, predicted)\n",
    "            confMatrix(cf_matrix=conf,pngName=\"NASNetMoibleClassifier/\"+\"_karisiklik_matris\"+str(index))\n",
    "            md1.save('NASNetMoibleClassifier/model.h5')\n",
    "\n",
    "        if (selected_cb==4):\n",
    "            model=benimModel()\n",
    "            model.summary()\n",
    "            md1 = train_model(model, x_train, Y_train,'benim/', epochs=3, verbose=1)\n",
    "            predicted = md1.predict(x_test).astype(\"int\")\n",
    "            conf = confusion_matrix(Y_test, predicted)\n",
    "            confMatrix(cf_matrix=conf,pngName=\"benim/\"+\"_karisiklik_matris\"+str(index))\n",
    "            md1.save('benim/model.h5')\n",
    "           \n",
    "\n",
    "                \n",
    "        index+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-02T14:23:30.456501Z",
     "iopub.status.idle": "2023-01-02T14:23:30.456818Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test prediction data preparation\n",
    "selected_cb=1\n",
    "esik=0.5\n",
    "if (selected_cb==1):\n",
    "    model = tf.keras.models.load_model('CNN/model.h5')\n",
    "    esik=0.165\n",
    "if (selected_cb==2):\n",
    "    model= tf.keras.models.load_model(\"VGGModel/model.h5\")\n",
    "    esik=0.75\n",
    "if (selected_cb==3):\n",
    "    model= tf.keras.models.load_model(\"NASNetMoibleClassifier/model.h5\")\n",
    "    esik=0.5\n",
    "if (selected_cb==4):\n",
    "    model=model.load_model(\"benim/model.h5\")\n",
    "    esik=0.5\n",
    "\n",
    "test_images = []\n",
    "for image in test_df.image.values:\n",
    "    test_images.append(image)\n",
    "X_test = np.array(test_images)\n",
    "#prediction on test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_test = (y_pred.flatten()>esik).astype('int8')\n",
    "# submission file preparation\n",
    "submission=pd.DataFrame({'id':test_df['id']})\n",
    "submission['has_cactus']=y_test\n",
    "#submitting the results\n",
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = (y_pred.flatten()>0.75).astype('int8')\n",
    "submission['has_cactus']=y_pred\n",
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf = confusion_matrix(X_test, predicted)\n",
    "confMatrix(cf_matrix=conf,pngName=\"_karisiklik_matris_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0.1, 0.7]\n",
    "plt.plot( y)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
